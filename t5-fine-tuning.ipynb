{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# T5 모델을 활용한 문장 요약 모델 미세 조정","metadata":{}},{"cell_type":"code","source":"%config Completer.use_jedi = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T07:38:47.892295Z","iopub.execute_input":"2024-12-11T07:38:47.892557Z","iopub.status.idle":"2024-12-11T07:38:47.917602Z","shell.execute_reply.started":"2024-12-11T07:38:47.892530Z","shell.execute_reply":"2024-12-11T07:38:47.916685Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T07:39:23.067284Z","iopub.execute_input":"2024-12-11T07:39:23.068067Z","iopub.status.idle":"2024-12-11T07:39:32.308009Z","shell.execute_reply.started":"2024-12-11T07:39:23.068035Z","shell.execute_reply":"2024-12-11T07:39:32.307137Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.26.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.6.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 뉴스 요약 데이터세트 불러오기\n\nimport numpy as np\nfrom datasets import load_dataset\n\nnews = load_dataset(\"argilla/news-summary\", split=\"test\")\ndf = news.to_pandas().sample(5000, random_state=42)[[\"text\", \"prediction\"]]\ndf[\"text\"] = \"summarize: \" + df[\"text\"]\ndf[\"prediction\"] = df[\"prediction\"].map(lambda x: x[0][\"text\"])\ntrain, valid, test = np.split(\n    df.sample(frac=1, random_state=42), [int(0.6 * len(df)), int(0.8 * len(df))]\n)\n\nprint(f\"source news: {train.text.iloc[0][:200]}\")\nprint(f\"summarization: {train.prediction.iloc[0][:50]}\")\nprint(len(train))\nprint(len(valid))\nprint(len(test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T07:48:23.912708Z","iopub.execute_input":"2024-12-11T07:48:23.913452Z","iopub.status.idle":"2024-12-11T07:48:29.464728Z","shell.execute_reply.started":"2024-12-11T07:48:23.913411Z","shell.execute_reply":"2024-12-11T07:48:29.463776Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3da7c4c57d02441a974c6fe9f66f6332"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-ebc48879f34571f6.parquet:   0%|          | 0.00/1.54M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc133f71abbb49ccbb66624ec89cb972"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-6227bd8eb10a9b50.parquet:   0%|          | 0.00/31.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0947e830e1724da19fbaed69409189d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf472fe795de4337886e98a3cbfe9c63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/20417 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8e92e9e968f4d1a950596f7126c8cf2"}},"metadata":{}},{"name":"stdout","text":"source news: summarize: DANANG, Vietnam (Reuters) - Russian President Vladimir Putin said on Saturday he had a normal dialogue with U.S. leader Donald Trump at a summit in Vietnam, and described Trump as civil, we\nsummarization: Putin says had useful interaction with Trump at Vi\n3000\n1000\n1000\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n  return bound(*args, **kwds)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nfrom transformers import T5Tokenizer\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.utils.data import RandomSampler, SequentialSampler\nfrom torch.nn.utils.rnn import pad_sequence\n\ndef make_dataset(data, tokenizer, device):\n    source = tokenizer(\n        text=data.text.tolist(),\n        padding=\"max_length\",\n        max_length=128,\n        pad_to_max_length=True,\n        truncation=True,\n        return_tensors=\"pt\"\n    )\n\n    target = tokenizer(\n        text=data.prediction.tolist(),\n        padding=\"max_length\",\n        max_length=128,\n        pad_to_max_length=True,\n        truncation=True,\n        return_tensors=\"pt\"\n    )\n    \n    source_ids = source[\"input_ids\"].squeeze().to(device)\n    source_mask = source[\"attention_mask\"].squeeze().to(device)\n    target_ids = target[\"input_ids\"].squeeze().to(device)\n    target_mask = target[\"attention_mask\"].squeeze().to(device)\n    return TensorDataset(source_ids, source_mask, target_ids, target_mask)\n\ndef get_dataloader(dataset, sampler, batch_size):\n    data_sampler = sampler(dataset)\n    dataloader = DataLoader(dataset, sampler=data_sampler, batch_size=batch_size)\n    return dataloader\n\nepochs = 5\nbatch_size = 8\ndevice = \"cuda\" if torch.cuda.is_available else \"cpu\"\ntokenizer = T5Tokenizer.from_pretrained(\n    pretrained_model_name_or_path=\"t5-small\"\n)\n\ntrain_dataset = make_dataset(train, tokenizer, device)\ntrain_dataloader = get_dataloader(train_dataset, RandomSampler, batch_size)\n\nvalid_dataset = make_dataset(valid, tokenizer, device)\nvalid_dataloader = get_dataloader(valid_dataset, SequentialSampler, batch_size)\n\ntest_dataset = make_dataset(test, tokenizer, device)\ntest_dataloader = get_dataloader(test_dataset, SequentialSampler, batch_size)\n\nprint(next(iter(train_dataloader)))\nprint(tokenizer.convert_ids_to_tokens(21603))\nprint(tokenizer.convert_ids_to_tokens(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T07:59:17.654560Z","iopub.execute_input":"2024-12-11T07:59:17.654902Z","iopub.status.idle":"2024-12-11T07:59:28.556555Z","shell.execute_reply.started":"2024-12-11T07:59:17.654872Z","shell.execute_reply":"2024-12-11T07:59:28.555673Z"}},"outputs":[{"name":"stdout","text":"[tensor([[21603,    10,  3087,  ..., 10148,    18,     1],\n        [21603,    10,  6827,  ...,     8, 13350,     1],\n        [21603,    10,  8747,  ...,  1661, 20653,     1],\n        ...,\n        [21603,    10,   549,  ...,    82,  3315,     1],\n        [21603,    10,   549,  ..., 14938,  2363,     1],\n        [21603,    10,     3,  ..., 10226, 20432,     1]], device='cuda:0'), tensor([[1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1],\n        ...,\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), tensor([[21986, 23655,     7,  ...,     0,     0,     0],\n        [ 9299,    31,     7,  ...,     0,     0,     0],\n        [  412,     5,   134,  ...,     0,     0,     0],\n        ...,\n        [ 2759,  8994, 13644,  ...,     0,     0,     0],\n        [ 4534,    31,     7,  ...,     0,     0,     0],\n        [12207, 20143,     7,  ...,     0,     0,     0]], device='cuda:0'), tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')]\n▁summarize\n:\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from torch import optim\nfrom transformers import T5ForConditionalGeneration\n\nmodel = T5ForConditionalGeneration.from_pretrained(\n    pretrained_model_name_or_path=\"t5-small\"\n).to(device)\noptimizer = optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T08:00:36.003392Z","iopub.execute_input":"2024-12-11T08:00:36.004056Z","iopub.status.idle":"2024-12-11T08:00:50.089678Z","shell.execute_reply.started":"2024-12-11T08:00:36.004024Z","shell.execute_reply":"2024-12-11T08:00:50.088716Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aee96eb20b34349bede17d48555ec77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fff6884025484121a32d16c5c50a24a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb0341a57e9e4338894d94120f646ae0"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nfrom torch import nn\n\ndef train(model, optimizer, dataloader):\n    model.train()\n    train_loss = 0.0\n\n    for source_ids, source_mask, target_ids, target_mask in dataloader:\n        decoder_input_ids = target_ids[:,:-1].contiguous()\n        labels = target_ids[:, 1:].clone().detach()\n        labels[target_ids[:, 1:] == tokenizer.pad_token_id] = -100\n\n        outputs = model(\n            input_ids=source_ids,\n            attention_mask=source_mask,\n            decoder_input_ids=decoder_input_ids,\n            labels=labels\n        )\n\n        loss = outputs.loss\n        train_loss += loss.item()\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    train_loss = train_loss / len(dataloader)\n    return train_loss\n    \ndef evaluation(model, dataloader):\n    with torch.no_grad():\n        model.eval()\n        val_loss = 0.0\n\n        for source_ids, source_mask, target_ids, target_mask in dataloader:\n            decoder_input_ids = target_ids[:, :-1].contiguous()\n            labels = target_ids[:, 1:].clone().detach()\n            labels[target_ids[:, 1:] == tokenizer.pad_token_id] = -100\n\n            outputs = model(\n                input_ids=source_ids,\n                attention_mask=source_mask,\n                decoder_input_ids=decoder_input_ids,\n                labels=labels,\n            )\n\n            loss = outputs.loss\n            val_loss += loss\n\n    val_loss = val_loss / len(dataloader)\n    return val_loss\n\nbest_loss = 10000\nfor epoch in range(epochs):\n    train_loss = train(model, optimizer, train_dataloader)\n    val_loss = evaluation(model, valid_dataloader)\n    print(f\"epoch {epoch + 1}: train loss: {train_loss:.4f} val loss: {val_loss:.4f}\")\n\n    if val_loss < best_loss:\n        best_loss = val_loss\n        torch.save(model.state_dict(), \"/kaggle/working/T5ForConditionalGeneration.pt\")\n        print(\"끝\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T08:39:01.443803Z","iopub.execute_input":"2024-12-11T08:39:01.444748Z","iopub.status.idle":"2024-12-11T08:42:19.113476Z","shell.execute_reply.started":"2024-12-11T08:39:01.444709Z","shell.execute_reply":"2024-12-11T08:42:19.112315Z"}},"outputs":[{"name":"stdout","text":"epoch 1: train loss: 3.1483 val loss: 2.7144\n끝\nepoch 2: train loss: 2.9226 val loss: 2.6273\n끝\nepoch 3: train loss: 2.8201 val loss: 2.5670\n끝\nepoch 4: train loss: 2.7603 val loss: 2.5245\n끝\nepoch 5: train loss: 2.6968 val loss: 2.4903\n끝\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
